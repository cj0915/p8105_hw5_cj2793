---
title: "p8105_hw5_cj2793"
author: "Chenyu Jin"
date: "2024-11-02"
output: github_document
---

```{r message = FALSE}
library(tidyverse)
set.seed(1)
```

# Problem 2

## Set design parameters according to the problem

```{r}
n <- 30
sigma <- 5
mu_values <- c(0:6)
iterations <- 5000
alpha <- 0.05
```

## Function to simulate data

```{r}
simulate_t_test <- function(mu, sigma = 5, n = 30) {
  x <- rnorm(n, mean = mu, sd = sigma)
  t_test_result <- t.test(x, mu = 0)
  tibble(
    estimate = t_test_result[["estimate"]],
    p_value = t_test_result[["p.value"]]
  )
}
```

## Run simulation for each value of mu

```{r}
simulation_results <- expand_grid(mu = mu_values, 
                                  iter = 1:iterations) |>
  mutate(
    result_df = map(mu, simulate_t_test)
  ) |>
  unnest(result_df)
```

## Calculate power for each mu value

```{r}
power_results <- simulation_results |>
  group_by(mu) |>
  summarize(power = mean(p_value < alpha))
```

## Plot power vs. true value of mu

```{r plot1}
power_results |>
  ggplot(aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Power of the One-Sample t-Test",
    x = "True Value of μ",
    y = "Power (Proportion of Null Rejected)"
  ) +
  theme_minimal()
```

The graph shows the relationship between the true value of μ and the power of the one-sample t-test. As the true value of μ increases, the power of the test also increases, indicating a higher probability of rejecting the null hypothesis when the effect size is larger.

## Average estimate of mu across all samples and only when null is rejected

```{r}
estimate_results <- simulation_results |>
  group_by(mu) |>
  summarize(
    avg_estimate_all = mean(estimate),
    avg_estimate_rejected = mean(estimate[p_value < alpha])
  )
```

## Plot average estimate vs. true value of mu

```{r plot2}
estimate_results |>
  ggplot(aes(x = mu)) +
  geom_line(aes(y = avg_estimate_all, color = "All Samples")) +
  geom_line(aes(y = avg_estimate_rejected, color = "Null Rejected")) +
  geom_point(aes(y = avg_estimate_all, color = "All Samples")) +
  geom_point(aes(y = avg_estimate_rejected, color = "Null Rejected")) +
  labs(
    title = "Average Estimate of μ vs. True Value of μ",
    x = "True Value of μ",
    y = "Average Estimate of μ",
    color = "Condition"
  ) +
  theme_minimal()

```

The graph shows the average estimate of μ across all samples and only for samples where the null hypothesis was rejected. The average estimate of μ for rejected tests tends to be higher than the true value, especially for smaller effect sizes, because only larger estimates pass the significance value alpha = 0.05.

# Problem 3

## 0. Import raw data

```{r message = FALSE}
homicide_df = read_csv(file = "data/homicide.csv", na = c("Unknown", "NA", "")) |>
  mutate(reported_date = as.Date(as.character(reported_date), format = "%Y%m%d"))
```

## 1. Describe the raw data

```{r}
summary(homicide_df)

homicide_df <- homicide_df |>
  mutate(city_state = str_c(city, state, sep = ", "))

homicide_summary <- homicide_df |>
  group_by(city) |>
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"),
                             na.rm = TRUE)
  )

homicide_summary |> knitr::kable()

```

The raw data consists of information on homicides across `r nrow(homicide_summary)` large U.S. cities, with `r nrow(homicide_df)` records. The dataset contains variables such as `reported_date`, `victim_last`, `victim_first`, `victim_race`, `victim_age`, `victim_sex`, `city`, `state`, `lat`, `lon`, and `disposition`. The reported_date ranges from 2007-01-01 to 2015-11-05, and victim ages range from 0 to 102, with some missing values. The disposition variable indicates the status of each case, with categories like "Closed without arrest" and "Open/No arrest" representing unsolved homicides.

## 2. `prop.test` for Baltimore, MD

```{r}
baltimore_data <- homicide_summary |> 
  filter(city == "Baltimore")

baltimore_prop_test <- prop.test(baltimore_data[['unsolved_homicides']],
                                 baltimore_data[['total_homicides']]) |>
  broom::tidy()

baltimore_results <- baltimore_prop_test |> 
  select(estimate, conf.low, conf.high)

baltimore_results |> knitr::kable()
```

## 3. `prop.test` for each of the cities

### Define a function to estimate the proportion of unsolved homicides

```{r}
estimate_unsolved_proportion <- function(unsolved, total) {
  prop_test_result <- prop.test(unsolved, total)
  broom::tidy(prop_test_result) |> 
    select(estimate, conf.low, conf.high)
}
```

### Apply the function to all cities

```{r}
homicide_test_summary <- homicide_summary |>
  mutate(
    prop_test_result = map2(unsolved_homicides, total_homicides, 
                            \(x, y) estimate_unsolved_proportion(x, y))
  ) |>
  unnest(prop_test_result)

homicide_test_summary  |> knitr::kable()
```

```{r plot3}
homicide_test_summary <- homicide_test_summary |>
  arrange(desc(estimate))

homicide_test_summary |> 
  ggplot(aes(x = reorder(city, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Proportion of Unsolved Homicides"
  ) +
  theme_minimal()

```

