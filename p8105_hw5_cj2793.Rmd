---
title: "p8105_hw5_cj2793"
author: "Chenyu Jin"
date: "2024-11-02"
output: github_document
---

```{r message = FALSE}
library(tidyverse)
set.seed(1)
```

# Problem 1

## Function to simulate birthdays, check for duplicates, and estimate the probability of shared birthdays

```{r}
estimate_birthday_probabilities <- function(group_sizes, n_simulations) {
  birthday_probabilities <- map_dbl(group_sizes, function(n) {
    mean(replicate(n_simulations, {
      birthdays <- sample(1:365, n, replace = TRUE)
      any(duplicated(birthdays))
    }))
  })
  
  birthday_results <- tibble(
    group_size = group_sizes,
    probability = birthday_probabilities
  )
  
  return(birthday_results)
}
```

## Simulation and plot

```{r problem 1 simulation plot}
group_sizes <- 2:50
n_simulations <- 10000

birthday_results <- estimate_birthday_probabilities(group_sizes, n_simulations)

birthday_results |> 
  ggplot(aes(x = group_size, y = probability)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Probability of Shared Birthdays by Group Size",
    x = "Group Size",
    y = "Probability of Shared Birthday"
  ) +
  theme_minimal()
```

Initially, the probability of a shared birthday is very low for small group sizes. However, as the group size grows, the probability rises rapidly. By the time the group size reaches around 23, the probability exceeds 50%, and by group size 50, the probability approaches 100%.

# Problem 2

## Set design parameters according to the problem

```{r}
n <- 30
sigma <- 5
mu_values <- c(0:6)
iterations <- 5000
alpha <- 0.05
```

## Function to simulate data

```{r}
simulate_t_test <- function(mu, sigma = 5, n = 30) {
  x <- rnorm(n, mean = mu, sd = sigma)
  t_test_result <- t.test(x, mu = 0)
  tibble(
    estimate = t_test_result[["estimate"]],
    p_value = t_test_result[["p.value"]]
  )
}
```

## Run simulation for each value of mu

```{r}
simulation_results <- expand_grid(mu = mu_values, 
                                  iter = 1:iterations) |>
  mutate(
    result_df = map(mu, simulate_t_test)
  ) |>
  unnest(result_df)
```

## Calculate power for each mu value

```{r}
power_results <- simulation_results |>
  group_by(mu) |>
  summarize(power = mean(p_value < alpha))
```

## Plot power vs. true value of mu

```{r plot1}
power_results |>
  ggplot(aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Power of the One-Sample t-Test",
    x = "True Value of μ",
    y = "Power (Proportion of Null Rejected)"
  ) +
  theme_minimal()
```

The graph shows the relationship between the true value of μ and the power of the one-sample t-test. As the true value of μ increases, the power of the test also increases, indicating a higher probability of rejecting the null hypothesis when the effect size is larger.

## Average estimate of mu across all samples and only when null is rejected

```{r}
estimate_results <- simulation_results |>
  group_by(mu) |>
  summarize(
    avg_estimate_all = mean(estimate),
    avg_estimate_rejected = mean(estimate[p_value < alpha])
  )
```

## Plot average estimate vs. true value of mu

```{r plot2}
estimate_results |>
  ggplot(aes(x = mu)) +
  geom_line(aes(y = avg_estimate_all, color = "All Samples")) +
  geom_line(aes(y = avg_estimate_rejected, color = "Null Rejected")) +
  geom_point(aes(y = avg_estimate_all, color = "All Samples")) +
  geom_point(aes(y = avg_estimate_rejected, color = "Null Rejected")) +
  labs(
    title = "Average Estimate of μ vs. True Value of μ",
    x = "True Value of μ",
    y = "Average Estimate of μ",
    color = "Condition"
  ) +
  theme_minimal()

```

The graph shows the average estimate of μ across all samples and only for samples where the null hypothesis was rejected. The average estimate of μ for rejected tests tends to be higher than the true value, especially for smaller effect sizes, because only larger estimates pass the significance value alpha = 0.05.

# Problem 3

## 0. Import raw data

```{r message = FALSE}
homicide_df = read_csv(file = "data/homicide.csv", na = c("Unknown", "NA", "")) |>
  mutate(reported_date = as.Date(as.character(reported_date), format = "%Y%m%d"))
```

## 1. Describe the raw data

```{r}
summary(homicide_df)

homicide_df <- homicide_df |>
  mutate(city_state = str_c(city, state, sep = ", "))

homicide_summary <- homicide_df |>
  group_by(city_state) |>
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"),
                             na.rm = TRUE)
  ) |>
  filter(city_state != "Tulsa, AL")

homicide_summary |> knitr::kable()

```

The raw data consists of information on homicides across `r nrow(homicide_summary)` large U.S. cities, with `r nrow(homicide_df)` records. The dataset contains variables such as `reported_date`, `victim_last`, `victim_first`, `victim_race`, `victim_age`, `victim_sex`, `city`, `state`, `lat`, `lon`, and `disposition`. The reported_date ranges from 2007-01-01 to 2015-11-05, and victim ages range from 0 to 102, with some missing values. The disposition variable indicates the status of each case, with categories like "Closed without arrest" and "Open/No arrest" representing unsolved homicides.

## 2. `prop.test` for Baltimore, MD

```{r}
baltimore_data <- homicide_summary |> 
  filter(city_state == "Baltimore, MD")

baltimore_prop_test <- prop.test(baltimore_data[['unsolved_homicides']],
                                 baltimore_data[['total_homicides']]) |>
  broom::tidy()

baltimore_results <- baltimore_prop_test |> 
  select(estimate, conf.low, conf.high)

baltimore_results |> knitr::kable()
```

## 3. `prop.test` for each of the cities

### Define a function to estimate the proportion of unsolved homicides

```{r}
estimate_unsolved_proportion <- function(unsolved, total) {
  prop_test_result <- prop.test(unsolved, total)
  broom::tidy(prop_test_result) |> 
    select(estimate, conf.low, conf.high)
}
```

### Apply the function to all cities

```{r}
homicide_test_summary <- homicide_summary |>
  mutate(
    prop_test_result = map2(unsolved_homicides, total_homicides, 
                            \(x, y) estimate_unsolved_proportion(x, y))
  ) |>
  unnest(prop_test_result)

homicide_test_summary  |> knitr::kable()
```

```{r plot3}
homicide_test_summary <- homicide_test_summary |>
  arrange(desc(estimate))

homicide_test_summary |> 
  ggplot(aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City, State",
    y = "Proportion of Unsolved Homicides"
  ) +
  theme_minimal()

```

